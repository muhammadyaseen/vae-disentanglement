{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f48882b",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "I created a dataset of three different shapes:\n",
    "\n",
    "1. Triangle \n",
    "2. Square\n",
    "3. Circle (approximated as a polygon with n=500 sides)\n",
    "\n",
    "It had 10,000 examples in total and every shape was (roughly) equally represented. \n",
    "\n",
    "## 1. On Clean Data\n",
    "\n",
    "This dataset is *without* any kind of noise. The only variation is in shape, and within shapes there is no variation. For example, all triangles are the same.\n",
    "\n",
    "Then I trained Vanilla VAE with 1 unit in the latent layer. \n",
    "Following is the plot of latent unit activation (mean of our learned latent dist).\n",
    "\n",
    "![three shapes result 1](three_shapes_clean.png \"Histogram of activatations on clean three shapes data\")\n",
    "\n",
    "As can be seen, there is very clear separation of three classes.\n",
    "\n",
    "\n",
    "And here are the reconstructions. \n",
    "Recons are generally very good and sharp, but some cheating behaviour (phantom square behing triangle) can be seen as well.\n",
    "\n",
    "![](recon_on_clean.png \"Reconstruction of Clean Data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fb398f",
   "metadata": {},
   "source": [
    "## 2. On Perturbed Data\n",
    "\n",
    "Then I repeated this experiment, but this time I added noise. The noise is added to the position of shape's center i.e. it offsets the square from center point by a disturbance d ~ N(3,1)\n",
    "\n",
    "Training and visualizing the means give us the following plot. This time the distributions are not as sharp, but they're still relatively compact. Square dist has been squeezed b/w circle and triangle dist.\n",
    "\n",
    "![three shapes result 1](three_shapes_noisy.png \"Histogram of activatations on clean three shapes data\")\n",
    "\n",
    "And here are the reconstructions on noisy dataset. Same cheating behaviour as before, but now the shapes are blurred as well.\n",
    "\n",
    "![Reconstruction of Noisy Data](recon_on_noisey.png \"Reconstruction of Noisy Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8150e194",
   "metadata": {},
   "source": [
    "## 3. On Perturbed Data with 2 Latents\n",
    "\n",
    "At this point I thought that network is being forced to use the same dist to represent center position as well (as it is no longer fixed because of noise). This could explain higher variance in resultant dists.\n",
    "\n",
    "To test this, I added one more latent unit with the assumption that network will try to capture the noise of center position in the second unit and keep first unit free of any interference due to noise.\n",
    "\n",
    "Since we now have 2 latent units, we can make a 2-D scatter plot of representations. As shown:\n",
    "\n",
    "![scatter of 2 latents](three_shapes_scatter.png \"Scatter Plot of Latent Acts in 2D\")\n",
    "\n",
    "The distributions are still compact, and we again see square dist being squeezed b/w circle and triangle.\n",
    "\n",
    "### Separate Activation Histograms for each Unit\n",
    "\n",
    "I also plotted the histogram of each unit separately to see how they differ.\n",
    "\n",
    "![two unit separate hist](three_shapes_2units.png \"Histogram of activatations two latent units, Separately.\")\n",
    "\n",
    "- Unit 1's histogram is the same as last time. We see more spread compared to clean data case.\n",
    "- Unit 2's histogram shows that distribution is same in all three classes. This is not surprising since the noise we added was same for each class. What *is* surprising is that this didn't have any effect on the spread of unit 1's distributions\n",
    "\n",
    "### Reconstructions\n",
    "\n",
    "And here are the recons when the network uses 2 units:\n",
    "![recond two units](recon_on_2ls.png \"Reconstructions when 2 latent units are allowed\")\n",
    "\n",
    "Recons look subjectively the same as in 1 unit case, perhaps slightly less blurred and network achieves a slightly lower loss value\n",
    "\n",
    "|Type | Loss |\n",
    "|:--------|-----------:|\n",
    "| Clean data (1 unit) | 0.0217\n",
    "| Noisy data (1 unit) | 0.06914\n",
    "| Noisy data (2 units) | 0.06613\n",
    "\n",
    "### Some Interesting things to note:\n",
    "    \n",
    "1. Both histograms are limited to the [-2,2] range, even though this range is not being enforced anywhere. We do enforce a similarity to N(0,1) via KL-divergence.\n",
    "2. The distribution corresponding to circle is the most spread out. This probably has to do with the fact that circle has the highest area among the three chosen shapes. This suggest that I should try out shapes with same (unit) area. I didn't enforce 'same area' constraint this time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b8d22d",
   "metadata": {},
   "source": [
    "## Recon comparison\n",
    "\n",
    "### clean data\n",
    "![recon_on_2ls](recon_on_clean.png \"Reconstructions when 2 latent units are allowed\")\n",
    "\n",
    "### noisy data (1 unit)\n",
    "![recon_on_2ls](recon_on_noisey.png \"Reconstructions when 2 latent units are allowed\")\n",
    "\n",
    "### noisy data (2 units)\n",
    "![recon_on_2ls](recon_on_2ls.png \"Reconstructions when 2 latent units are allowed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50de1608",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
