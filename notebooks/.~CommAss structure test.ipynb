{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92a3dec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Saarbrucken\\EDA_Research\\vae-disentanglement\\disentanglement_lib_pl\n"
     ]
    }
   ],
   "source": [
    "cd D:\\Saarbrucken\\EDA_Research\\vae-disentanglement\\disentanglement_lib_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c54c28bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from architectures import encoders, decoders\n",
    "from common.ops import Flatten3D, Unsqueeze3D, Reshape\n",
    "from torch.nn import functional as F\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7568203f",
   "metadata": {},
   "source": [
    "# Multiscale + GNN structure test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211a0ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd D:\\Saarbrucken\\EDA_Research\\vae-disentanglement\\disentanglement_lib_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6052ccde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from common.ops import Flatten3D, Unsqueeze3D, Reshape\n",
    "\n",
    "class MultiScaleEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder as used in 'Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations'\n",
    "    \"\"\"\n",
    "    def __init__(self, feature_dim, in_channels, num_nodes):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Number of features per scale used by each node to compute initial node features\n",
    "        # 3 means 3 features from each scale level will be used\n",
    "        self.NUM_SCALES = 3\n",
    "        self.feature_dim = feature_dim\n",
    "        self.num_nodes = num_nodes\n",
    "        self.features_to_take = self.feature_dim // self.num_nodes\n",
    "        self.batch_size = None\n",
    "\n",
    "        # in / out feature maps at each scale\n",
    "        self.scale_3_in, self.scale_3_out = in_channels, 32\n",
    "        self.scale_2_in, self.scale_2_out = 32, 32\n",
    "        self.scale_1_in, self.scale_1_out = 32, 64\n",
    "\n",
    "        # coarsest scale - outputs maps of shape B, \n",
    "        self.scale_3 = nn.Sequential(\n",
    "            nn.Conv2d(self.scale_3_in, self.scale_3_out, 4, 2), # B, 32, 31 x 31\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.scale_3_feats = nn.Sequential(\n",
    "            Flatten3D(),\n",
    "            nn.Linear(self.scale_3_out * 31 * 31, self.feature_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        # mid scale - outputs maps of shape B, \n",
    "        self.scale_2 = nn.Sequential(\n",
    "            nn.Conv2d(self.scale_2_in, self.scale_2_out, 4, 2), # B, 32, 14 x 14\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.scale_2_feats = nn.Sequential(\n",
    "            Flatten3D(),\n",
    "            nn.Linear(self.scale_2_out * 14 * 14, self.feature_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        # finest scale - outs maps of shape B,\n",
    "        self.scale_1 = nn.Sequential(\n",
    "            nn.Conv2d(self.scale_1_in, self.scale_1_out, 4, 2), # B, 64, 6 x 6\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.scale_1_feats = nn.Sequential(\n",
    "            Flatten3D(),\n",
    "            nn.Linear(self.scale_1_out * 6 * 6, self.feature_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        self.batch_size = x.shape[0]\n",
    "        \n",
    "        scale_3_x = self.scale_3(x)\n",
    "        scale_3_feats = self.scale_3_feats(scale_3_x)\n",
    "\n",
    "        scale_2_x = self.scale_2(scale_3_x)\n",
    "        scale_2_feats = self.scale_2_feats(scale_2_x)\n",
    "\n",
    "        scale_1_x = self.scale_1(scale_2_x)\n",
    "        scale_1_feats = self.scale_1_feats(scale_1_x)\n",
    "        #print(scale_3_feats.shape)\n",
    "        #print(scale_2_feats.shape)\n",
    "        #print(scale_1_feats.shape)\n",
    "        \n",
    "        # Just stacking gives the shape (NUM_SCALES, batch_size, feature_dim). Hence, we need to permute to get \n",
    "        # (batch_size, feature_dim, NUM_SCALES)\n",
    "        multi_scale_feats = torch.stack([scale_3_feats, scale_2_feats, scale_1_feats]).permute(1,2,0)\n",
    "        # (batch_size, V, NUM_SCALES * features_to_take)\n",
    "        multi_scale_feats = multi_scale_feats.reshape(self.batch_size, self.num_nodes, self.NUM_SCALES * self.features_to_take )\n",
    "        \n",
    "        # reshape like this so that they can be associated with each latent node\n",
    "        return multi_scale_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dddf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_enc = MultiScaleEncoder(4*2, 1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1a9300",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = ms_enc(torch.randn(2,1,64,64))\n",
    "print(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13eca36f",
   "metadata": {},
   "source": [
    "## Testing Prior GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505c65f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGNNLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Can be used to implement GNNs for P(Z|epsilon, A) or Q(Z|X,A)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_node_feat_dim, out_node_feat_dim, adj_mat, is_final_layer=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_node_feat_dim = in_node_feat_dim\n",
    "        self.out_node_feat_dim = out_node_feat_dim\n",
    "        self.is_final_layer = is_final_layer\n",
    "        self.A = adj_mat\n",
    "\n",
    "        self.num_neighbours = self.A.sum(dim=-1, keepdims=True)\n",
    "        self.projection = nn.Linear(self.in_node_feat_dim, self.out_node_feat_dim)\n",
    "    \n",
    "    def forward(self, node_feats):\n",
    "        \n",
    "        node_feats = self.projection(node_feats)\n",
    "        node_feats = torch.matmul(self.A, node_feats)\n",
    "        node_feats = node_feats / self.num_neighbours\n",
    "        \n",
    "        if self.is_final_layer:\n",
    "            # split into mu and sigma\n",
    "            node_feats_mu, node_feats_logvar = node_feats.chunk(2, dim=2)\n",
    "            return node_feats_mu, node_feats_logvar\n",
    "        else:\n",
    "            node_feats = torch.tanh(node_feats)\n",
    "            return node_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e185d595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 nodes with topology given in A\n",
    "dist_param_dim = 2\n",
    "batch, V, node_feat_dim = 2, 4, 1\n",
    "A = torch.Tensor([\n",
    "    [1., 0., 1., 1.],\n",
    "    [0., 1., 0., 1.],\n",
    "    [0., 0., 1., 0.],\n",
    "    [0., 0., 0., 1.]\n",
    "])\n",
    "\n",
    "# sample V exogenous vars per batch\n",
    "E = torch.randn(size=(batch, V, node_feat_dim))\n",
    "\n",
    "print(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2fd8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass thru K GNN layers\n",
    "\n",
    "prior_gnn = nn.Sequential(\n",
    "    SimplePriorGNNLayer(in_node_feat_dim=1, out_node_feat_dim=2*dist_param_dim, adj_mat=A),\n",
    "    SimplePriorGNNLayer(in_node_feat_dim=2*dist_param_dim, out_node_feat_dim=2*dist_param_dim, adj_mat=A, is_final_layer=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ac0990",
   "metadata": {},
   "outputs": [],
   "source": [
    "mus, logvars = prior_gnn(E)\n",
    "print(mus)\n",
    "\n",
    "print(logvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4c9d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p.shape)\n",
    "mus, logvars = p.chunk(2, dim=2)\n",
    "\n",
    "\n",
    "print(mus.shape, mus)\n",
    "\n",
    "print(logvars.shape, logvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f39ac9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in prior_layer1.parameters(): print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8579dce",
   "metadata": {},
   "source": [
    "## Testing Encoder GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1eea6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adj_mat_from_adj_list(adjacency_list):\n",
    "    \n",
    "    num_nodes = len(adjacency_list)\n",
    "\n",
    "    # initialize with self-connections\n",
    "    A = np.zeros(shape=(num_nodes, num_nodes)) + np.eye(num_nodes)\n",
    "\n",
    "    for node_idx, parent_list in enumerate(adjacency_list):\n",
    "        print(parent_list)\n",
    "        for parent_node_idx in parent_list:\n",
    "            A[parent_node_idx, node_idx] = 1.0\n",
    "\n",
    "    return torch.from_numpy(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5a8f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_list = [(),(),(0,),(0,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b6971a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "get_adj_mat_from_adj_list(adjacency_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae8f58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.Tensor([\n",
    "    [1., 0., 1., 1.],\n",
    "    [0., 1., 0., 1.],\n",
    "    [0., 0., 1., 0.],\n",
    "    [0., 0., 0., 1.]\n",
    "])\n",
    "A.T.sum(dim=-1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fcf56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_divergence_diag_mu_var_per_node(mu, logvar, target_mu, target_logvar):\n",
    "    \n",
    "    # Calculate per node kldloss\n",
    "\n",
    "    # input have shape (Batch, V, node_feats)\n",
    "    # output has shape (Batch, V, 1)\n",
    "    kld = -0.5 * ( 1 - target_logvar + logvar -\n",
    "                  ((target_mu - mu) * target_logvar.exp().pow(-1) * (target_mu - mu)) - \n",
    "                    (target_logvar.exp().pow(-1)*logvar.exp())\n",
    "            )#.sum(2, keepdims=True).mean(0)\n",
    "    return kld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53daf995",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_mu = torch.Tensor(\n",
    "    [ [[0., 0.],\n",
    "      [0., 0.]],\n",
    "\n",
    "        [[0., 0.],\n",
    "         [0., 0.]]\n",
    "    ]\n",
    ")\n",
    "\n",
    "target_logvar = torch.Tensor(\n",
    "    [ [[0., 0.],\n",
    "      [0., 0.]],\n",
    "\n",
    "        [[0., 0.],\n",
    "         [0., 0.]]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e35ddc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = torch.Tensor(\n",
    "    [ [[1., 0.],\n",
    "      [0., 1.]],\n",
    "\n",
    "        [[1., 0.],\n",
    "         [0., 0.95]]\n",
    "    ]\n",
    ")\n",
    "\n",
    "logvar = torch.Tensor(\n",
    "    [ [[0.5, 0.],\n",
    "      [0., 0.]],\n",
    "\n",
    "        [[0.5, 0.],\n",
    "         [0., 0.]]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1005d502",
   "metadata": {},
   "outputs": [],
   "source": [
    "kld = kl_divergence_diag_mu_var_per_node(mu, logvar, target_mu, target_logvar)\n",
    "print(kld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a291de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kld.sum(2, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf20f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_node_kld = kld.sum(2, keepdims=True).mean(0)\n",
    "print(per_node_kld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7af1eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for kld_node in per_node_kld:\n",
    "    print(kld_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8d61c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import dag_utils\n",
    "\n",
    "alist = pickle.load(open(r\"D:\\Saarbrucken\\EDA_Research\\vae-disentanglement\\adjacency_matrices\\dsprites_correlated.pkl\", 'rb'))\n",
    "A = dag_utils.get_adj_mat_from_adj_list(alist)\n",
    "\n",
    "print(A)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdadfb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "nf = torch.arange(25).type(torch.FloatTensor).view(5,5)\n",
    "print(nf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27656ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.matmul(A.T, nf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c776ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGNNLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Can be used to implement GNNs for P(Z|epsilon, A) or Q(Z|X,A)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_node_feat_dim, out_node_feat_dim, adj_mat, is_final_layer=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_node_feat_dim = in_node_feat_dim\n",
    "        self.out_node_feat_dim = out_node_feat_dim\n",
    "        self.is_final_layer = is_final_layer\n",
    "        self.A = adj_mat.T # TODO:\n",
    "\n",
    "        self.num_neighbours = self.A.sum(dim=-1, keepdims=True)\n",
    "        self.projection = nn.Linear(self.in_node_feat_dim, self.out_node_feat_dim)\n",
    "    \n",
    "    def forward(self, node_feats):\n",
    "        \n",
    "        self.A = self.A.to(node_feats.device)\n",
    "        self.num_neighbours = self.num_neighbours.to(node_feats.device)\n",
    "        \n",
    "        node_feats = self.projection(node_feats)\n",
    "        print(node_feats)\n",
    "        node_feats = torch.matmul(self.A, node_feats)\n",
    "        print(node_feats)\n",
    "        node_feats = node_feats / self.num_neighbours\n",
    "        print(node_feats)\n",
    "        \n",
    "        if self.is_final_layer:\n",
    "            # split into mu and sigma\n",
    "            node_feats_mu, node_feats_logvar = node_feats.chunk(2, dim=2)\n",
    "            return node_feats_mu, node_feats_logvar\n",
    "        else:\n",
    "            node_feats = torch.tanh(node_feats)\n",
    "            return node_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe25a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from common.special_modules import SimpleGNNLayer\n",
    "\n",
    "V, ifd, ofd =5, 2, 4\n",
    "\n",
    "#inp = torch.randn(size=(1, V, ifd))\n",
    "\n",
    "inp = torch.arange(10).type(torch.FloatTensor).view(1, V, ifd)\n",
    "print(inp)\n",
    "print(\"input shape: \", inp.shape)\n",
    "\n",
    "prior_gnn = SimpleGNNLayer(ifd, ofd, A.T, is_final_layer=True)\n",
    "print(\"Linear layer mat shape: \", prior_gnn.projection.weight.data.shape)\n",
    "prior_gnn.projection.weight.data = torch.Tensor(\n",
    "        [[1., 0.],\n",
    "        [0., 1.],\n",
    "        [1., 0.],\n",
    "        [0., 1.]]\n",
    ")\n",
    "prior_gnn.projection.bias.data = torch.zeros(ofd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299a890d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"input: \", inp)\n",
    "out = prior_gnn(inp)\n",
    "\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efb757a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(batch, num_nodes, num_feat_dim)\n",
    "\n",
    "mus = torch.randn(1, 5, 2)\n",
    "print(mus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d04154",
   "metadata": {},
   "outputs": [],
   "source": [
    "mus.mean(0).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d221a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for node_idx in range(5):\n",
    "    for k in range(2):\n",
    "        print(f\"node {node_idx}, comp {k}, : {mus[:, node_idx, k]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c53c801",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_gnn.num_neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "695e1ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1.]])\n",
      "GNNBasedConceptStructuredVAE Model Initialized\n"
     ]
    }
   ],
   "source": [
    "from gnncsvae_experiment import GNNCSVAEExperiment\n",
    "from collections import defaultdict, namedtuple\n",
    "import models\n",
    "\n",
    "ModelParams = namedtuple('ModelParams', [\"z_dim\", \"l_dim\", \"num_labels\" , \"in_channels\", \n",
    "                                        \"image_size\", \"batch_size\", \"w_recon\", \"w_kld\", \"kl_warmup_epochs\",\n",
    "                                         \"adjacency_matrix\"])\n",
    "\n",
    "\n",
    "algo_name = \"GNNBasedConceptStructuredVAE\"\n",
    "checkpoint_path = r\"D:\\Saarbrucken\\EDA_Research\\vae-disentanglement\\models\\gnncsvae.ckpt\"\n",
    "z_dim = 5\n",
    "\n",
    "model_params = ModelParams(\n",
    "        [z_dim], 6, 0, 1, 64, 64, 1.0, 1.0, 0,\n",
    "    r\"D:\\Saarbrucken\\EDA_Research\\vae-disentanglement\\adjacency_matrices\\dsprites_correlated.pkl\"\n",
    ")\n",
    "exp_params = dict(\n",
    "        in_channels=1,\n",
    "        image_size=64,\n",
    "        LR=1e-4,\n",
    "        weight_decay=0.0,       \n",
    "        dataset=\"dsprites_correlated\",\n",
    "        datapath=r\"D:\\Saarbrucken\\EDA_Research\\vae-disentanglement\\datasets\",\n",
    "        droplast=True,        \n",
    "        batch_size=64,\n",
    "        num_workers=0,\n",
    "        pin_memory=False,\n",
    "        seed=123,\n",
    "        evaluation_metrics=None,\n",
    "        visdom_on=False,\n",
    "        save_dir=None,\n",
    "        max_epochs=1,\n",
    "        l_zero_reg=False\n",
    ")\n",
    "vae_model_class = getattr(models, algo_name)\n",
    "vae_model = vae_model_class(model_params)\n",
    "\n",
    "vae_experiment = GNNCSVAEExperiment.load_from_checkpoint(\n",
    "            checkpoint_path,\n",
    "            vae_model=vae_model, \n",
    "            params=exp_params,\n",
    "            dataset_params=dict(correlation_strength=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b171ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets the vae_experimen.sample_loader var\n",
    "#vae_experiment.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94595b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
      "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize [CorrelatedDSpritesDataset] with 737280 examples. Shape (737280, 64, 64).\n"
     ]
    }
   ],
   "source": [
    "from common.notebook_utils import get_configured_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "os.environ['DISENTANGLEMENT_LIB_DATA'] = r\"D:\\Saarbrucken\\EDA_Research\\vae-disentanglement\\datasets\"\n",
    "\n",
    "dataset = get_configured_dataset(\"dsprites_correlated\")\n",
    "sample_loader = DataLoader(dataset, batch_size=64, shuffle = False, drop_last=True)\n",
    "\n",
    "test_input, test_label = next(iter(sample_loader))\n",
    "fwd_pass_results = vae_experiment.model.forward(test_input, current_device=test_input.device, labels = test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dd1c096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['x_recon', 'prior_mu', 'prior_logvar', 'posterior_mu', 'posterior_logvar', 'latents_predicted'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fwd_pass_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39436e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2693,  0.0669,  0.7291, -0.0036,  1.4615],\n",
       "        [ 0.2693,  0.0670,  0.7291, -0.0036,  1.4615],\n",
       "        [ 0.2693,  0.0670,  0.7291, -0.0036,  1.4614],\n",
       "        [ 0.2693,  0.0670,  0.7291, -0.0036,  1.4614],\n",
       "        [ 0.2693,  0.0670,  0.7291, -0.0036,  1.4614]],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fwd_pass_results['prior_mu'][1,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e20db40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2693,  0.0670,  0.7291, -0.0036,  1.4614],\n",
       "        [ 0.2693,  0.0670,  0.7291, -0.0036,  1.4614],\n",
       "        [ 0.2692,  0.0671,  0.7291, -0.0036,  1.4614],\n",
       "        [ 0.2692,  0.0671,  0.7291, -0.0036,  1.4614],\n",
       "        [ 0.2693,  0.0670,  0.7291, -0.0036,  1.4614]],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fwd_pass_results['prior_mu'][2,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c947456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-9.7433,  0.2114, -9.2024, -9.2940, -8.7455],\n",
       "        [-9.7430,  0.2121, -9.2024, -9.2941, -8.7451],\n",
       "        [-9.7434,  0.2114, -9.2026, -9.2942, -8.7456],\n",
       "        [-9.7433,  0.2115, -9.2025, -9.2941, -8.7455],\n",
       "        [-9.7429,  0.2119, -9.2023, -9.2939, -8.7451]],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fwd_pass_results['prior_logvar'][1,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d1dc720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-9.7433,  0.2116, -9.2025, -9.2941, -8.7454],\n",
       "        [-9.7439,  0.2110, -9.2029, -9.2945, -8.7461],\n",
       "        [-9.7424,  0.2124, -9.2018, -9.2936, -8.7446],\n",
       "        [-9.7425,  0.2124, -9.2020, -9.2937, -8.7447],\n",
       "        [-9.7432,  0.2114, -9.2025, -9.2940, -8.7455]],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fwd_pass_results['prior_logvar'][2,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd5fc57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "0c1e42d09abd9a7c7967c6caf04ac65128c9e19aa5355439d6e17d7b03582b55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
