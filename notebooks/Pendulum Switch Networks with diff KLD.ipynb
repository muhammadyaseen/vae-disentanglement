{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca764d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd D:\\\\Saarbrucken\\\\EDA_Research\\\\vae-disentanglement\\\\disentanglement_lib_pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd994d5",
   "metadata": {},
   "source": [
    "## Keeping everything else (bs, LR, w_recon, w_sup, prior type etc.) the same we just varied w_kld = 5,10,15,20,25 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f7700f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import namedtuple\n",
    "from matplotlib import cm as mpl_colormaps\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "\n",
    "import torch\n",
    "import torchvision.utils as vutils\n",
    "import torchvision.transforms.functional as T\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import models\n",
    "from common.data_loader import DSpritesDataset, ThreeShapesDataset, ContinumDataset\n",
    "#from common import notebook_utils\n",
    "from common import utils\n",
    "#from common.notebook_utils import *\n",
    "from common import notebook_utils as nbutils\n",
    "from common.utils import CenteredNorm\n",
    "from gnncsvae_experiment import GNNCSVAEExperiment\n",
    "from common.ops import reparametrize\n",
    "# Change figure aesthetics\n",
    "%matplotlib inline\n",
    "sns.set_context('talk', font_scale=1.2, rc={'lines.linewidth': 1.5})\n",
    "np.set_printoptions(suppress=True,precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027cc388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these two will be used any time we load a saved checkppoint\n",
    "\n",
    "PROJECT_ROOT = r\"D:\\Saarbrucken\\EDA_Research\\vae-disentanglement\"\n",
    "datapath = os.path.join(PROJECT_ROOT, \"datasets\")\n",
    "os.environ['DISENTANGLEMENT_LIB_DATA'] = datapath\n",
    "\n",
    "ModelParams = namedtuple('ModelParams', [\"z_dim\", \"l_dim\", \"num_labels\" , \"in_channels\", \n",
    "                                        \"image_size\", \"batch_size\", \"w_recon\", \"w_kld\", \"w_sup_reg\", \"kl_warmup_epochs\",\n",
    "                                         \"adjacency_matrix\", \"loss_terms\", \"use_loss_weights\",\n",
    "                                        \"controlled_capacity_increase\", \"iterations_c\", \"max_capacity\", \"dset_name\", \n",
    "                                         \"num_indept_nodes\"\n",
    "                                        ])\n",
    "\n",
    "ExpParams = dict(\n",
    "        in_channels=-1,\n",
    "        image_size=64,\n",
    "        LR=1e-4,\n",
    "        weight_decay=0.0,       \n",
    "        dataset=None,\n",
    "        datapath=datapath,\n",
    "        droplast=True,        \n",
    "        batch_size=64,\n",
    "        num_workers=0,\n",
    "        pin_memory=False,\n",
    "        seed=123,\n",
    "        evaluation_metrics=None,\n",
    "        visdom_on=False,\n",
    "        save_dir=None,\n",
    "        max_epochs=1,\n",
    "        l_zero_reg=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0d707b",
   "metadata": {},
   "source": [
    "# KLD = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4e1f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the learned model here\n",
    "\n",
    "algo_name = \"GNNBasedConceptStructuredVAE\"\n",
    "checkpoint_path = os.path.join(PROJECT_ROOT, \"models\", \"v8\", \"version_8\", \"checkpoints\", \"pendulum144ep1dim_indept.ckpt\")\n",
    "z_dim = 1\n",
    "channels = 3\n",
    "l_dim = 4\n",
    "num_nodes = 4\n",
    "num_indept_nodes = 3\n",
    "dataset = \"pendulum\"\n",
    "current_device = torch.device(\"cuda:0\")\n",
    "\n",
    "# prep params\n",
    "model_params = ModelParams(\n",
    "        [z_dim], l_dim, 0, channels, 64, 64, 0.80, 0.15, 1.0, 0,\n",
    "        os.path.join(PROJECT_ROOT, \"adjacency_matrices\", f\"{dataset}.pkl\"),\n",
    "        ['aux_classification'], False,\n",
    "        False, 0, 0, \"pendulum\", num_indept_nodes\n",
    ")\n",
    "\n",
    "ExpParams['channels'] = channels\n",
    "\n",
    "# load model\n",
    "vae_model_class = getattr(models, algo_name)\n",
    "vae_model = vae_model_class(model_params)\n",
    "\n",
    "vae_experiment = GNNCSVAEExperiment.load_from_checkpoint(\n",
    "            checkpoint_path,\n",
    "            vae_model=vae_model, \n",
    "            params=ExpParams,\n",
    "            dataset_params=None).to(current_device)\n",
    "\n",
    "# load data\n",
    "dataset = get_configured_dataset(dataset)\n",
    "sample_loader = DataLoader(dataset, batch_size=64, shuffle = False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62627663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backup current direct of logs for this expr\n",
    "# run to comparable epochs \n",
    "\n",
    "# Learned Posterior activations\n",
    "# Learned Prior activations\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
