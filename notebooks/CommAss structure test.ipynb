{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92a3dec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Saarbrucken\\EDA_Research\\vae-disentanglement\\disentanglement_lib_pl\n"
     ]
    }
   ],
   "source": [
    "cd D:\\Saarbrucken\\EDA_Research\\vae-disentanglement\\disentanglement_lib_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c54c28bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# genernal\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from architectures import encoders, decoders\n",
    "from common.ops import Flatten3D, Unsqueeze3D, Reshape\n",
    "from torch.nn import functional as F\n",
    "import pickle\n",
    "from common import dag_utils\n",
    "\n",
    "# model loading\n",
    "from gnncsvae_experiment import GNNCSVAEExperiment\n",
    "from collections import defaultdict, namedtuple\n",
    "import models\n",
    "from common.notebook_utils import get_configured_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "# for plotting stuff\n",
    "from matplotlib import cm as mpl_colormaps\n",
    "from common.utils import CenteredNorm\n",
    "import matplotlib.pyplot as plt \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7568203f",
   "metadata": {},
   "source": [
    "# Multiscale + GNN structure test "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13eca36f",
   "metadata": {},
   "source": [
    "## Testing Prior GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbe25a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from common.special_modules import SimpleGNNLayer\n",
    "\n",
    "# V, ifd, ofd =5, 2, 4\n",
    "\n",
    "# #inp = torch.randn(size=(1, V, ifd))\n",
    "\n",
    "# inp = torch.arange(10).type(torch.FloatTensor).view(1, V, ifd)\n",
    "# print(inp)\n",
    "# print(\"input shape: \", inp.shape)\n",
    "\n",
    "# prior_gnn = SimpleGNNLayer(ifd, ofd, A.T, is_final_layer=True)\n",
    "# print(\"Linear layer mat shape: \", prior_gnn.projection.weight.data.shape)\n",
    "# prior_gnn.projection.weight.data = torch.Tensor(\n",
    "#         [[1., 0.],\n",
    "#         [0., 1.],\n",
    "#         [1., 0.],\n",
    "#         [0., 1.]]\n",
    "# )\n",
    "# prior_gnn.projection.bias.data = torch.zeros(ofd)\n",
    "# print(\"input: \", inp)\n",
    "# out = prior_gnn(inp)\n",
    "# print(out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef802fef",
   "metadata": {},
   "source": [
    "# Load model and test prior components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "695e1ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ModelParams = namedtuple('ModelParams', [\"z_dim\", \"l_dim\", \"num_labels\" , \"in_channels\", \n",
    "                                        \"image_size\", \"batch_size\", \"w_recon\", \"w_kld\", \"kl_warmup_epochs\",\n",
    "                                         \"adjacency_matrix\"])\n",
    "\n",
    "\n",
    "algo_name = \"GNNBasedConceptStructuredVAE\"\n",
    "checkpoint_path = r\"D:\\Saarbrucken\\EDA_Research\\vae-disentanglement\\models\\gnncsvae.ckpt\"\n",
    "z_dim = 5\n",
    "\n",
    "model_params = ModelParams(\n",
    "        [z_dim], 6, 0, 1, 64, 64, 1.0, 1.0, 0,\n",
    "    r\"D:\\Saarbrucken\\EDA_Research\\vae-disentanglement\\adjacency_matrices\\dsprites_correlated.pkl\"\n",
    ")\n",
    "exp_params = dict(\n",
    "        in_channels=1,\n",
    "        image_size=64,\n",
    "        LR=1e-4,\n",
    "        weight_decay=0.0,       \n",
    "        dataset=\"dsprites_correlated\",\n",
    "        datapath=r\"D:\\Saarbrucken\\EDA_Research\\vae-disentanglement\\datasets\",\n",
    "        droplast=True,        \n",
    "        batch_size=64,\n",
    "        num_workers=0,\n",
    "        pin_memory=False,\n",
    "        seed=123,\n",
    "        evaluation_metrics=None,\n",
    "        visdom_on=False,\n",
    "        save_dir=None,\n",
    "        max_epochs=1,\n",
    "        l_zero_reg=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729ce918",
   "metadata": {},
   "source": [
    "# Model with 5-dim node feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6eb544",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_model_class = getattr(models, algo_name)\n",
    "vae_model = vae_model_class(model_params)\n",
    "\n",
    "vae_experiment = GNNCSVAEExperiment.load_from_checkpoint(\n",
    "            checkpoint_path,\n",
    "            vae_model=vae_model, \n",
    "            params=exp_params,\n",
    "            dataset_params=dict(correlation_strength=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e8a4741",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n",
      "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize [CorrelatedDSpritesDataset] with 737280 examples. Shape (737280, 64, 64).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "os.environ['DISENTANGLEMENT_LIB_DATA'] = r\"D:\\Saarbrucken\\EDA_Research\\vae-disentanglement\\datasets\"\n",
    "\n",
    "dataset = get_configured_dataset(\"dsprites_correlated\")\n",
    "sample_loader = DataLoader(dataset, batch_size=64, shuffle = False, drop_last=True)\n",
    "\n",
    "test_input, test_label = next(iter(sample_loader))\n",
    "fwd_pass_results = vae_experiment.model.forward(test_input, current_device=test_input.device, labels = test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "411e62e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['x_recon', 'prior_mu', 'prior_logvar', 'posterior_mu', 'posterior_logvar', 'latents_predicted'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fwd_pass_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a9e8e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2693,  0.0669,  0.7291, -0.0036,  1.4615],\n",
       "        [ 0.2693,  0.0670,  0.7291, -0.0036,  1.4615],\n",
       "        [ 0.2693,  0.0670,  0.7291, -0.0036,  1.4614],\n",
       "        [ 0.2693,  0.0670,  0.7291, -0.0036,  1.4614],\n",
       "        [ 0.2693,  0.0670,  0.7291, -0.0036,  1.4614]],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fwd_pass_results['prior_mu'][1,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053b8051",
   "metadata": {},
   "source": [
    "## Check projection matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5e9706e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 29)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x28292872160>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Ws = [vae_experiment.model.prior_gnn[i].projection.weight.detach() for i in range(3)]\n",
    "Ws_to_plot = torch.cat(Ws, dim = 1).numpy()\n",
    "print(Ws_to_plot.shape)\n",
    "fig, axs = plt.subplots(figsize=(10, 6))\n",
    "fig.tight_layout(pad=0)\n",
    "axs.margins(0)\n",
    "plt.axis('off')\n",
    "plt.imshow(Ws_to_plot, cmap=mpl_colormaps.coolwarm, norm=CenteredNorm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "691d0b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 29)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x282928b6e50>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Ws = [vae_experiment.model.encoder_gnn[i].projection.weight.detach() for i in range(3)]\n",
    "Ws_to_plot = torch.cat(Ws, dim = 1).numpy()\n",
    "print(Ws_to_plot.shape)\n",
    "fig, axs = plt.subplots(figsize=(10, 6))\n",
    "fig.tight_layout(pad=0)\n",
    "axs.margins(0)\n",
    "plt.axis('off')\n",
    "plt.imshow(Ws_to_plot, cmap=mpl_colormaps.coolwarm, norm=CenteredNorm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ff640b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([10, 9]), torch.Size([10, 10]), torch.Size([10, 10])]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " [vae_experiment.model.prior_gnn[i].projection.weight.size() for i in range(3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ca27d7",
   "metadata": {},
   "source": [
    "# For the 2D node feat dim model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "684b5881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1.]])\n",
      "GNNBasedConceptStructuredVAE Model Initialized\n"
     ]
    }
   ],
   "source": [
    "algo_name = \"GNNBasedConceptStructuredVAE\"\n",
    "checkpoint_path = r\"D:\\Saarbrucken\\EDA_Research\\vae-disentanglement\\models\\gnncsvae2d.ckpt\"\n",
    "z_dim = 2\n",
    "model_params = ModelParams(\n",
    "        [z_dim], 6, 0, 1, 64, 64, 1.0, 1.0, 0,\n",
    "    r\"D:\\Saarbrucken\\EDA_Research\\vae-disentanglement\\adjacency_matrices\\dsprites_correlated.pkl\"\n",
    ")\n",
    "vae_model_class = getattr(models, algo_name)\n",
    "vae_model = vae_model_class(model_params)\n",
    "\n",
    "vae_experiment = GNNCSVAEExperiment.load_from_checkpoint(\n",
    "            checkpoint_path,\n",
    "            vae_model=vae_model, \n",
    "            params=exp_params,\n",
    "            dataset_params=dict(correlation_strength=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfefe65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 17)\n",
      "(4, 17)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2225dc8f310>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Ws = [vae_experiment.model.prior_gnn[i].projection.weight.detach() for i in range(3)]\n",
    "Ws_to_plot = torch.cat(Ws, dim = 1).numpy()\n",
    "print(Ws_to_plot.shape)\n",
    "fig, axs = plt.subplots(figsize=(10, 6))\n",
    "fig.tight_layout(pad=0)\n",
    "axs.margins(0)\n",
    "plt.axis('off')\n",
    "plt.imshow(Ws_to_plot, cmap=mpl_colormaps.coolwarm, norm=CenteredNorm())\n",
    "\n",
    "Ws = [vae_experiment.model.encoder_gnn[i].projection.weight.detach() for i in range(3)]\n",
    "Ws_to_plot = torch.cat(Ws, dim = 1).numpy()\n",
    "print(Ws_to_plot.shape)\n",
    "fig, axs = plt.subplots(figsize=(10, 6))\n",
    "fig.tight_layout(pad=0)\n",
    "axs.margins(0)\n",
    "plt.axis('off')\n",
    "plt.imshow(Ws_to_plot, cmap=mpl_colormaps.coolwarm, norm=CenteredNorm())\n",
    "\n",
    "# Red==positive, Blue==negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "679601ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0663, -0.0145,  0.0393, -0.0600, -0.0453,  0.0603,  0.0362, -0.0366,\n",
       "          0.0034],\n",
       "        [ 0.0825, -0.0195,  0.0502, -0.0784, -0.0591,  0.0795,  0.0479, -0.0504,\n",
       "          0.0041],\n",
       "        [ 0.0316, -0.0059,  0.0186, -0.0286, -0.0209,  0.0289,  0.0167, -0.0171,\n",
       "          0.0021],\n",
       "        [ 0.0882, -0.0196,  0.0523, -0.0808, -0.0611,  0.0812,  0.0480, -0.0512,\n",
       "          0.0043]], requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_experiment.model.prior_gnn[0].projection.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2860bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.5789,  0.6704,  0.5819, -0.1446],\n",
       "        [-0.3088, -0.1422,  0.3604,  0.2173],\n",
       "        [-0.4159,  1.0702,  0.5456, -0.4264],\n",
       "        [-0.3753,  0.2776,  1.3673, -0.1371]], requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_experiment.model.prior_gnn[1].projection.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42161b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0908,  0.1481, -0.0526,  0.4951],\n",
       "        [-1.6003, -1.2836, -1.1983, -0.9343],\n",
       "        [ 0.1036, -1.0648,  0.0742,  1.5846],\n",
       "        [ 1.8579, -1.8139, -1.3088,  1.8840]], requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_experiment.model.encoder_gnn[2].projection.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9fec202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input feats:  tensor([[[-7.9969e-01, -1.1550e+00,  9.6412e-01,  1.2225e+00, -9.8180e-01,\n",
      "           4.7582e-01, -2.7427e-01,  2.0615e-03, -6.3219e-01],\n",
      "         [-2.3088e-01,  1.0195e+00,  2.3654e-02, -3.3703e-01,  5.4476e-01,\n",
      "          -2.2254e-01, -2.0557e+00, -4.2023e-01, -1.2114e+00],\n",
      "         [ 7.9600e-03,  3.3948e+00,  7.6689e-01,  1.4326e-01, -5.8459e-01,\n",
      "          -9.2519e-02, -4.6156e-01,  5.5915e-01,  1.2877e+00],\n",
      "         [-4.2749e-01, -1.7315e-01,  6.3546e-01,  7.3383e-01, -2.1482e-01,\n",
      "          -5.4844e-01, -3.4685e-01,  1.0338e+00,  1.1010e+00],\n",
      "         [-1.7646e+00,  7.5123e-02, -1.6798e+00,  1.2652e-01, -1.2977e+00,\n",
      "          -2.8057e-01,  1.4096e+00, -1.5187e+00,  2.5298e-01]]])\n",
      "Projected feats:  tensor([[[ 0.3271, -1.0143, -0.7150,  0.3834],\n",
      "         [ 0.2277, -1.1469, -0.7584,  0.2514],\n",
      "         [ 0.2987, -1.0593, -0.7223,  0.3427],\n",
      "         [ 0.2229, -1.1561, -0.7620,  0.2404],\n",
      "         [ 0.2955, -1.0452, -0.7299,  0.3452]]])\n",
      "Exchanged feats:  tensor([[[ 0.3271, -1.0143, -0.7150,  0.3834],\n",
      "         [ 0.2277, -1.1469, -0.7584,  0.2514],\n",
      "         [ 0.2987, -1.0593, -0.7223,  0.3427],\n",
      "         [ 0.2608, -1.1077, -0.7422,  0.2915],\n",
      "         [ 0.2955, -1.0452, -0.7299,  0.3452]]])\n",
      "Tanh() feats:  tensor([[[ 0.3159, -0.7676, -0.6138,  0.3657],\n",
      "         [ 0.2239, -0.8167, -0.6401,  0.2463],\n",
      "         [ 0.2901, -0.7854, -0.6184,  0.3299],\n",
      "         [ 0.2551, -0.8032, -0.6304,  0.2836],\n",
      "         [ 0.2872, -0.7799, -0.6230,  0.3321]]])\n",
      "Input feats:  tensor([[[ 0.3159, -0.7676, -0.6138,  0.3657],\n",
      "         [ 0.2239, -0.8167, -0.6401,  0.2463],\n",
      "         [ 0.2901, -0.7854, -0.6184,  0.3299],\n",
      "         [ 0.2551, -0.8032, -0.6304,  0.2836],\n",
      "         [ 0.2872, -0.7799, -0.6230,  0.3321]]])\n",
      "Projected feats:  tensor([[[-2.3713, -0.0920, -1.6461, -2.3221],\n",
      "         [-2.3490, -0.0920, -1.6239, -2.3208],\n",
      "         [-2.3658, -0.0909, -1.6417, -2.3187],\n",
      "         [-2.3578, -0.0920, -1.6331, -2.3207],\n",
      "         [-2.3635, -0.0920, -1.6381, -2.3227]]])\n",
      "Exchanged feats:  tensor([[[-2.3713, -0.0920, -1.6461, -2.3221],\n",
      "         [-2.3490, -0.0920, -1.6239, -2.3208],\n",
      "         [-2.3658, -0.0909, -1.6417, -2.3187],\n",
      "         [-2.3618, -0.0914, -1.6374, -2.3197],\n",
      "         [-2.3635, -0.0920, -1.6381, -2.3227]]])\n",
      "Tanh() feats:  tensor([[[-0.9827, -0.0917, -0.9283, -0.9809],\n",
      "         [-0.9819, -0.0917, -0.9252, -0.9809],\n",
      "         [-0.9825, -0.0907, -0.9277, -0.9808],\n",
      "         [-0.9824, -0.0912, -0.9271, -0.9809],\n",
      "         [-0.9824, -0.0917, -0.9272, -0.9810]]])\n",
      "Input feats:  tensor([[[-0.9827, -0.0917, -0.9283, -0.9809],\n",
      "         [-0.9819, -0.0917, -0.9252, -0.9809],\n",
      "         [-0.9825, -0.0907, -0.9277, -0.9808],\n",
      "         [-0.9824, -0.0912, -0.9271, -0.9809],\n",
      "         [-0.9824, -0.0917, -0.9272, -0.9810]]])\n",
      "Projected feats:  tensor([[[-0.7692, -0.1696, -4.7082, -0.0494],\n",
      "         [-0.7688, -0.1698, -4.7036, -0.0483],\n",
      "         [-0.7686, -0.1695, -4.7064, -0.0494],\n",
      "         [-0.7688, -0.1696, -4.7059, -0.0491],\n",
      "         [-0.7691, -0.1696, -4.7066, -0.0490]]])\n",
      "Exchanged feats:  tensor([[[-0.7692, -0.1696, -4.7082, -0.0494],\n",
      "         [-0.7688, -0.1698, -4.7036, -0.0483],\n",
      "         [-0.7686, -0.1695, -4.7064, -0.0494],\n",
      "         [-0.7687, -0.1696, -4.7062, -0.0493],\n",
      "         [-0.7691, -0.1696, -4.7066, -0.0490]]])\n"
     ]
    }
   ],
   "source": [
    "prior_gnn_out = None\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    exogen_samples = torch.randn(size=(1, vae_experiment.model.num_nodes, vae_experiment.model.encoder_cnn.out_feature_dim))   \n",
    "    prior_gnn_out = vae_experiment.model.prior_gnn(exogen_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9739e548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4093, -0.7022, -0.5794,  0.4828],\n",
       "         [ 0.4093, -0.7076, -0.5766,  0.4833],\n",
       "         [ 0.4480, -0.6749, -0.5656,  0.5306],\n",
       "         [ 0.2955, -0.7814, -0.6187,  0.3378],\n",
       "         [ 0.3965, -0.7163, -0.5839,  0.4648]],\n",
       "\n",
       "        [[ 0.4339, -0.6893, -0.5708,  0.5119],\n",
       "         [ 0.3732, -0.7306, -0.5929,  0.4403],\n",
       "         [ 0.5568, -0.5555, -0.5158,  0.6565],\n",
       "         [ 0.4293, -0.6876, -0.5723,  0.5080],\n",
       "         [ 0.2707, -0.7933, -0.6268,  0.3073]]], grad_fn=<TanhBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# already after the first projection, values are very similar\n",
    "vae_experiment.model.prior_gnn[0](exogen_samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "0c1e42d09abd9a7c7967c6caf04ac65128c9e19aa5355439d6e17d7b03582b55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
