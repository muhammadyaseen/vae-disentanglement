{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92a3dec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Saarbrucken\\EDA_Research\\vae-disentanglement\\disentanglement_lib_pl\n"
     ]
    }
   ],
   "source": [
    "cd D:\\Saarbrucken\\EDA_Research\\vae-disentanglement\\disentanglement_lib_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c54c28bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from architectures import encoders, decoders\n",
    "from common.ops import Flatten3D, Unsqueeze3D, Reshape\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5d67862",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = getattr(encoders, 'SimpleGaussianConv64CommAss')(10,3,64)\n",
    "dec = getattr(decoders, 'SimpleConv64CommAss')(10,3,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c561a346",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.rand(size=[1,3,64,64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82291afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "enc = nn.Sequential(\n",
    "    nn.Conv2d(1, 5, 2, 1, 0), # B,5,2,2\n",
    "    nn.ReLU(True),\n",
    "    Flatten3D(), # B,5x2x2\n",
    "    nn.Linear(20, 10),\n",
    "    nn.Linear(10, num_latent)\n",
    ")\n",
    "\n",
    "dec = nn.Sequential(\n",
    "    Unsqueeze3D(),\n",
    "    nn.Conv2d(num_latent, 20, 1, 1), \n",
    "    nn.ReLU(True),\n",
    "    Reshape([5, 2, 2]),\n",
    "    nn.ConvTranspose2d(5, 1, 2, 1, 0)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1bd8b82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 3, 3]) tensor([[[[-0.1105, -0.2154, -0.3674],\n",
      "          [-0.1536, -0.5432, -0.3171],\n",
      "          [-0.3573, -0.3726, -0.3949]]]],\n",
      "       grad_fn=<SlowConvTranspose2DBackward>)\n"
     ]
    }
   ],
   "source": [
    "o = Unsqueeze3D()(o)\n",
    "#print(o.shape, o)\n",
    "o = nn.Conv2d(2, 20, 1, 1)(o)\n",
    "o = nn.ReLU(True)(o)\n",
    "#print(o.shape, o)\n",
    "o = Reshape([5,2, 2])(o)\n",
    "#print(o.shape, o)\n",
    "o = nn.ConvTranspose2d(5, 1, 2, 1, 0)(o)\n",
    "print(o.shape, o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7568203f",
   "metadata": {},
   "source": [
    "# Multiscale + GNN structure test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "211a0ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Saarbrucken\\EDA_Research\\vae-disentanglement\\disentanglement_lib_pl\n"
     ]
    }
   ],
   "source": [
    "cd D:\\Saarbrucken\\EDA_Research\\vae-disentanglement\\disentanglement_lib_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6052ccde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from common.ops import Flatten3D, Unsqueeze3D, Reshape\n",
    "\n",
    "class MultiScaleEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder as used in 'Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations'\n",
    "    \"\"\"\n",
    "    def __init__(self, feature_dim, in_channels, num_nodes):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Number of features per scale used by each node to compute initial node features\n",
    "        # 3 means 3 features from each scale level will be used\n",
    "        self.NUM_SCALES = 3\n",
    "        self.feature_dim = feature_dim\n",
    "        self.num_nodes = num_nodes\n",
    "        self.features_to_take = self.feature_dim // self.num_nodes\n",
    "        self.batch_size = None\n",
    "\n",
    "        # in / out feature maps at each scale\n",
    "        self.scale_3_in, self.scale_3_out = in_channels, 32\n",
    "        self.scale_2_in, self.scale_2_out = 32, 32\n",
    "        self.scale_1_in, self.scale_1_out = 32, 64\n",
    "\n",
    "        # coarsest scale - outputs maps of shape B, \n",
    "        self.scale_3 = nn.Sequential(\n",
    "            nn.Conv2d(self.scale_3_in, self.scale_3_out, 4, 2), # B, 32, 31 x 31\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.scale_3_feats = nn.Sequential(\n",
    "            Flatten3D(),\n",
    "            nn.Linear(self.scale_3_out * 31 * 31, self.feature_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        # mid scale - outputs maps of shape B, \n",
    "        self.scale_2 = nn.Sequential(\n",
    "            nn.Conv2d(self.scale_2_in, self.scale_2_out, 4, 2), # B, 32, 14 x 14\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.scale_2_feats = nn.Sequential(\n",
    "            Flatten3D(),\n",
    "            nn.Linear(self.scale_2_out * 14 * 14, self.feature_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        # finest scale - outs maps of shape B,\n",
    "        self.scale_1 = nn.Sequential(\n",
    "            nn.Conv2d(self.scale_1_in, self.scale_1_out, 4, 2), # B, 64, 6 x 6\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.scale_1_feats = nn.Sequential(\n",
    "            Flatten3D(),\n",
    "            nn.Linear(self.scale_1_out * 6 * 6, self.feature_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        self.batch_size = x.shape[0]\n",
    "        \n",
    "        scale_3_x = self.scale_3(x)\n",
    "        scale_3_feats = self.scale_3_feats(scale_3_x)\n",
    "\n",
    "        scale_2_x = self.scale_2(scale_3_x)\n",
    "        scale_2_feats = self.scale_2_feats(scale_2_x)\n",
    "\n",
    "        scale_1_x = self.scale_1(scale_2_x)\n",
    "        scale_1_feats = self.scale_1_feats(scale_1_x)\n",
    "        #print(scale_3_feats.shape)\n",
    "        #print(scale_2_feats.shape)\n",
    "        #print(scale_1_feats.shape)\n",
    "        \n",
    "        # Just stacking gives the shape (3, batch_size, feature_dim). Hence, we need to permute tp get \n",
    "        # (batch_size, feature_dim, 3)\n",
    "        multi_scale_feats = torch.stack([scale_3_feats, scale_2_feats, scale_1_feats]).permute(1,2,0)\n",
    "        \n",
    "        multi_scale_feats = multi_scale_feats.reshape(self.batch_size, self.num_nodes, self.NUM_SCALES * self.features_to_take )\n",
    "        \n",
    "        # reshape like this so that they can be associated with each latent node\n",
    "        return multi_scale_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "66dddf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_enc = MultiScaleEncoder(4*2, 1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "eb1a9300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.3083, -0.1329,  0.0334,  0.2024,  0.0683,  0.0298],\n",
      "         [-0.1563,  0.0509,  0.0678,  0.1451, -0.1596,  0.0435],\n",
      "         [-0.1692, -0.0438, -0.0202, -0.1336,  0.1160, -0.0684],\n",
      "         [ 0.0177,  0.0900, -0.0045, -0.1646,  0.1573,  0.0504]],\n",
      "\n",
      "        [[ 0.2070,  0.0479,  0.0158, -0.0309,  0.0621,  0.0077],\n",
      "         [ 0.2464,  0.0283,  0.0510, -0.3034,  0.0586,  0.0516],\n",
      "         [-0.1682,  0.0111, -0.0081,  0.2839, -0.0977, -0.0650],\n",
      "         [-0.0549,  0.0296,  0.0189,  0.1485,  0.0469,  0.0219]]],\n",
      "       grad_fn=<UnsafeViewBackward>)\n",
      "torch.Size([2, 4, 6])\n"
     ]
    }
   ],
   "source": [
    "out = ms_enc(torch.randn(2,1,64,64))\n",
    "print(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b75f2b3",
   "metadata": {},
   "source": [
    "## Testing Prior GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "505c65f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplePriorGNNLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements GNN for P(Z|epsilon, A)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_node_feat_dim, out_node_feat_dim, adj_mat, is_final_layer=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_node_feat_dim = in_node_feat_dim\n",
    "        self.out_node_feat_dim = out_node_feat_dim\n",
    "        self.is_final_layer = is_final_layer\n",
    "        self.A = adj_mat\n",
    "\n",
    "        self.num_neighbours = self.A.sum(dim=-1, keepdims=True)\n",
    "        self.projection = nn.Linear(self.in_node_feat_dim, self.out_node_feat_dim)\n",
    "    \n",
    "    def forward(self, node_feats):\n",
    "        \n",
    "        node_feats = self.projection(node_feats)\n",
    "        node_feats = torch.matmul(self.A, node_feats)\n",
    "        node_feats = node_feats / self.num_neighbours\n",
    "        # I think this should only happen in the final layer?\n",
    "        node_feats = torch.tanh(node_feats)\n",
    "                \n",
    "        if self.is_final_layer:\n",
    "            # I think this split and reparam needs to happen only in the last layer\n",
    "            \n",
    "            # split into mu and sigma\n",
    "            node_feats_mu, node_feats_logvar = node_feats.chunk(2, dim=2)\n",
    "            \n",
    "            # reparameterize\n",
    "            #eps = torch.randn(size=(node_feats[1]))\n",
    "            #node_feats_dist_params = node_feats_mu + eps * node_feats_logvar\n",
    "            \n",
    "            return node_feats_mu, node_feats_logvar\n",
    "            \n",
    "        return node_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7eb56ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.2551e+00],\n",
      "         [ 1.5454e+00],\n",
      "         [-6.6605e-03],\n",
      "         [ 1.7545e+00]],\n",
      "\n",
      "        [[-2.2148e-01],\n",
      "         [ 2.4578e-03],\n",
      "         [-2.3859e-01],\n",
      "         [-2.6712e+00]]])\n"
     ]
    }
   ],
   "source": [
    "# 4 nodes with topology given in A\n",
    "dist_param_dim = 2\n",
    "batch, V, node_feat_dim = 2, 4, 1\n",
    "A = torch.Tensor([\n",
    "    [1., 0., 1., 1.],\n",
    "    [0., 1., 0., 1.],\n",
    "    [0., 0., 1., 0.],\n",
    "    [0., 0., 0., 1.]\n",
    "])\n",
    "\n",
    "# sample V exogenous vars per batch\n",
    "E = torch.randn(size=(batch, V, node_feat_dim))\n",
    "\n",
    "print(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1952b473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass thru K GNN layers\n",
    "\n",
    "prior_gnn = nn.Sequential(\n",
    "    SimplePriorGNNLayer(in_node_feat_dim=1, out_node_feat_dim=2*dist_param_dim, adj_mat=A),\n",
    "    SimplePriorGNNLayer(in_node_feat_dim=2*dist_param_dim, out_node_feat_dim=2*dist_param_dim, adj_mat=A, is_final_layer=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7653c6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.2724,  0.4389],\n",
      "         [ 0.3510,  0.4798],\n",
      "         [ 0.1645,  0.3794],\n",
      "         [ 0.3544,  0.4811]],\n",
      "\n",
      "        [[ 0.0453,  0.3144],\n",
      "         [-0.0102,  0.2849],\n",
      "         [ 0.1325,  0.3601],\n",
      "         [-0.0374,  0.2759]]], grad_fn=<SplitBackward>)\n",
      "tensor([[[ 0.4508, -0.4678],\n",
      "         [ 0.4374, -0.5903],\n",
      "         [ 0.4674, -0.2716],\n",
      "         [ 0.4367, -0.5945]],\n",
      "\n",
      "        [[ 0.4864, -0.0281],\n",
      "         [ 0.4954,  0.0863],\n",
      "         [ 0.4720, -0.2065],\n",
      "         [ 0.5013,  0.1387]]], grad_fn=<SplitBackward>)\n"
     ]
    }
   ],
   "source": [
    "mus, logvars = prior_gnn(E)\n",
    "print(mus)\n",
    "\n",
    "print(logvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1bd112cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 4])\n",
      "torch.Size([2, 4, 2]) tensor([[[0.0000, 0.3792],\n",
      "         [0.0000, 0.4417],\n",
      "         [0.0000, 0.4282],\n",
      "         [0.0000, 0.3839]],\n",
      "\n",
      "        [[0.0000, 0.2568],\n",
      "         [0.0000, 0.1476],\n",
      "         [0.0000, 0.3002],\n",
      "         [0.0000, 0.1480]]], grad_fn=<SplitBackward>)\n",
      "torch.Size([2, 4, 2]) tensor([[[0.5665, 0.0000],\n",
      "         [0.5798, 0.0000],\n",
      "         [0.5667, 0.0000],\n",
      "         [0.5591, 0.0000]],\n",
      "\n",
      "        [[0.5909, 0.0000],\n",
      "         [0.6183, 0.0000],\n",
      "         [0.5801, 0.0000],\n",
      "         [0.6182, 0.0000]]], grad_fn=<SplitBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(p.shape)\n",
    "mus, logvars = p.chunk(2, dim=2)\n",
    "\n",
    "\n",
    "print(mus.shape, mus)\n",
    "\n",
    "print(logvars.shape, logvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c04df7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1122],\n",
      "        [ 0.5648],\n",
      "        [-0.3765],\n",
      "        [ 0.2321]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.9310,  0.2116,  0.6767,  0.8433], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for p in prior_layer1.parameters(): print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae0fec9",
   "metadata": {},
   "source": [
    "## Testing Encoder GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4ab003",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGNNEncoderLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements GNN for Q(Z|X,A)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_node_feat_dim, out_node_feat_dim, adj_mat, is_final_layer=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_node_feat_dim = in_node_feat_dim\n",
    "        self.out_node_feat_dim = out_node_feat_dim\n",
    "        self.A = adj_mat\n",
    "        self.is_final_layer = is_final_layer\n",
    "\n",
    "        self.num_neighbours = self.A.sum(dim=-1, keepdims=True)\n",
    "        self.projection = nn.Linear(self.in_node_feat_dim, self.out_node_feat_dim)\n",
    "\n",
    "    def forward(self, node_feats):\n",
    "        # Num neighbours = number of incoming edges\n",
    "        \n",
    "        # for the first layer node-feats will be multi_scale_features from encoder\n",
    "        \n",
    "        node_feats = self.projection(node_feats)\n",
    "        node_feats = torch.matmul(self.A, node_feats)\n",
    "        node_feats = node_feats / self.num_neighbours\n",
    "        node_feats = torch.tanh(node_feats)\n",
    "        \n",
    "        if self.is_final_layer:\n",
    "            # I think this split and reparam needs to happen only in the last layer\n",
    "            \n",
    "            # split into mu and sigma\n",
    "            node_feats_mu, node_feats_logvar = node_feats.chunk(2, dim=2)\n",
    "            \n",
    "            # reparameterize\n",
    "            #eps = torch.randn(size=(node_feats[1]))\n",
    "            #node_feats_dist_params = node_feats_mu + eps * node_feats_logvar\n",
    "            \n",
    "            return node_feats_mu, node_feats_logvar\n",
    "        \n",
    "        return node_feats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "0c1e42d09abd9a7c7967c6caf04ac65128c9e19aa5355439d6e17d7b03582b55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
