They use what they have termed a "SCM Prior". This is a DAG structure over the latent variables / concepts.

They do use a prior GNN which uses the structure from the given, assumed SCM


They model interventions over latent variables.

Do they use an encoder GNN ?

In the paper there's no explanation of why the units learn the concepts they do. There's probably an implication that they do so because they're being supervised by respective labels... but is that really enough ?

