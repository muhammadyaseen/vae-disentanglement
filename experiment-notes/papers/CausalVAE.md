- how are $g_i$ instantiated? - afaik the paper doesn't detail it
- how is the prior instantiated ? 
- If they learn $A$, it should mean that they don't start with the structure (e.g. in DEAR where where they start with a binary adj mat and then learn the weights)

#### Summary
- Generative factors with semantics are not necessarily independent. Instead, there might be an underlying causal structure
- Propose CausalVAE, which includes a Causal Layer to transform independent exogenous factors into causal endogenous ones that correspond to causally related concepts in data
- Causal representations learned by CausalVAE are semantically interpretable, and  their causal relationship as a DAG is identified with good accuracy
- CausalVAE model is able to generate counterfactual data through “do-operation” to the causal factors

| Variable / Concept      | Comment / Detail |
| ----------- | ----------- |
| $A$ - Binary adj. mat. provided for gen. tasks. Weights are learned      | $A$  - Structure is learned in "pre-train" stage via DAG constraint    |
| $X$   | Image        |
| $Z$   | Latent        |
| $\epsilon$ | Ind. exogen. vars used in Prior   |
|  $u$ | Label associated with latent $z_i$ and $u_i = \mathbb{E}(z_i \vert X)$ since $z_i \sim \mathcal{N}(z_i ;  u_i, 1)$ |
| Prior   |  $p_\theta(\epsilon, z \vert u)  = \mathcal{N}(0,I) \times \prod_i^n \mathcal{N}(z_i ;  \{u_i, 1\})$ |
| SCM | Linear SCM $\textbf{z} = \textbf{A}^T \textbf{z} + \epsilon = (I - \textbf{A}^T)^{-1} \epsilon$  <br>  $\epsilon \sim \mathcal{N}(0,I)$ and <br> $z_i = g_i(A_i \odot z; \eta_i) + \epsilon_i$. <br>Couldn't find how they are instantiating $g_i$
| Objective | $\mathcal{L} = -ELBO + \alpha H(A) + \beta l_u + \gamma l_m$   <br> ELBO =  $\mathbb{E}_{q_\mathcal{X}}[\mathbb{E}_{q_\phi(z \vert x,u)} [\log p_\theta(x \vert z)]$ <br> $- \mathcal{D}(q_\phi(\epsilon \vert x, u) \vert \vert p(\epsilon))$ <br> $- \mathcal{D}(q_\phi(z\vert x, u) \vert \vert p_\theta(z \vert u))$ |
|Learning $A$| Pre-train step for learning $A$ <br> $\min l_u = \mathbb{E}_{q_D} \vert \vert u - A^T u \vert \vert^2_2$ s.t <br> $H(A)=0$|
| Datasets | Pendulum, CelebA-4, Flow  |


#### Section 3 - Causal Disentanglement in VAE
- A Causal Layer, which essentially describes a SCM is introduced to a conventional VAE network. 
- The Causal Layer transforms the independent exogenous factors to causal ndogenous factors corresponding to causally related concepts of interest.
- A mask mechanism is then used to propagate the effect of parental variables to their children, mimicking the assignment operation of SCMs. 
- Such a Causal Layer is the key to supporting intervention or “do-operation”

#### 3.1 - Transforming Ind. Exogen Factors into Causal Reprs
Transforming $\epsilon$ to structured $z$.

In addition to the encoder and the decoder, we introduce a SCM layer to learn causal representations.

Though a general nonlinear SCM is preferred, for simplicity, in this work, the Causal Layer exactly implements a Linear SCM: 
$$\textbf{z} = \textbf{A}^T \textbf{z} + \epsilon = (I - \textbf{A}^T)^{-1} \epsilon  \;\;\;\; \epsilon \sim \mathcal{N}(0,I)\;\;\;\; \text{eq. 1}$$
- $A$ is the parameters to be learned in this layer
- $\epsilon$ are the latent exogenous independent vars
- $z$ are the latent endogenous variables with semantics / representation of $n$ concepts
- We treat both $\epsilon$ and $z$ as latent vars

We adopt additional information $u$ associated with the true causal concepts as  
supervising signal. (Related to: [[DEAR#3 2 - Supervised regularizer]]).

It is used in 2 ways:
- Firstly, we propose a conditional prior $p(z|u)$ to regularize the learned posterior of $z$. This guarantees that the learned model belongs to an identifiable family. 
- Secondly, we also leverage $u$ to learn the causal structure $A$.

### 3.2 - SCM Layer / Causal Layer
"Once the causal representation $z$ is obtained, it passes through a Mask Layer to reconstruct itself." 
(<span class="remark">Confusion bw Mask Layer and Causal Layer</span>)
(<span class="remark">If z's have already been obtained, why do we need to pass them thru this layer to reconstruct? I think these z's are not semantically aligned with the concepts and represent some intermediate state. They only become semantically aligned / meaningful after passing thru this layer</span>) 
Note that this step resembles a SCM which depicts how children are  generated by their corresponding parental variables.
- This layer makes intervention or ”do-operation” possible
- The adj mat $A$ is weighted such that each column $A_i \in \mathbb{R}^k$ and $A_{ji}$ encodes causal strength from $z_j$ to $z_i$.
- They also model a set of mild, invertible non-linear functions $g_1,\ldots,g_k$ that map parental vars to child vars. (Related: [[DEAR#Implementation of the SCM details from Appendix]]). Hence: 
$$z_i = g_i(A_i \odot z; \eta_i) + \epsilon_i\;\;\;\; \text{eq. 2}$$
- $g_i$ is a non linear function
- $\eta_i$ are the params of $g_i$
- By minimizing the reconstruction error, the adjacency matrix $A$ and the parameter $\eta_i$ of the mild nonlinear function $g_i$ are trained. (Similar to params of transformation $f_2$ in [[DEAR]]?)

<span class="remark">Paraphrasing of part of caption of Fig. 2 below</span>
- Causal Layer transforms $\epsilon$ into causal representation $z$ (eq 1) with cond. prior dist $p(z\vert u)$
- Mast Layer is then applied to these causal reprs $z$ "to resemble the SCM in eq 2"

### 3.3 - A Probabilistic Generative Model for CausalVAE 

Model is parameterized by $\theta = (f, h, C, T, \lambda)$
- $f(z)$ is the decoder
- $h(x,u)$ is the encoder
- $C = (I - A^T)^{-1}$
- $T(z) := ( \mu(z), \sigma(z))$
- $\lambda = (\lambda_1(u) = u, \lambda_2 = 1)$

<u>Assuming the following decoding and encoding processes</u>

$$x = f(z) + \xi$$
$$\epsilon = h(x,u) + \zeta$$

$$p_\theta(x,z,\epsilon|u) = p_\theta(x|z,\epsilon,u) \times p_\theta(\epsilon, z |u)$$
Where they instantiate:
$$ \begin{equation}
p_\theta(\epsilon, z |u)  = p(\epsilon) \times p_\theta(z |u)
\end{equation}
$$
$$ \begin{equation}
p_\theta(\epsilon, z |u)  = \mathcal{N}(0,I) \times \prod_i^n p_\theta(z_i | u_i)
\end{equation}
$$
$$ \begin{equation}
p_\theta(\epsilon, z |u)  = \mathcal{N}(0,I) \times \prod_i^n \mathcal{N}(z_i ;  \lambda_1(u_i), \lambda_2^2(u_i))
\end{equation}
$$
$$ \begin{equation}
p_\theta(\epsilon, z |u)  = \mathcal{N}(0,I) \times \prod_i^n \mathcal{N}(z_i ;  u_i, 1)
\end{equation}
$$
Essentially, somewhat like [[DEAR#3 2 - Supervised regularizer]], they have $\mathbb{E}(z_i|X) = u_i$

### Learning Strategy

The ELBO objective is: (Proof in appendix)

$$ 
\begin{align}
	\mathbb{E}_{q_\mathcal{X}}[\mathbb{E}_{q_\phi(z \vert x,u)} [\log p_\theta(x \vert z)] & \\ - \mathcal{D}(q_\phi(\epsilon \vert x, u) \vert \vert p(\epsilon)) & \\ - \mathcal{D}(q_\phi(z\vert x, u) \vert \vert p_\theta(z \vert u))
\end{align}
$$

How is $q_\phi(z\vert x, u)$ and $q_\phi(\epsilon \vert x, u)$ implemented in the network ?

### 6 - Experiments
- The results shown on the datasets (Pendulum, Flow, CelebA-Smile, CelebA-Beard) consist of 4 concepts.
<span class="remark">I'm not sure how it was actually implemented. When using CelebA-Smile dataset how do they model other latent attrs that they don't supervise?</span>

We expect that the pattern of the manipulated concept will be fixed across all images under the same intervention. 
- Pendulum: For example, when we intervene the `PENDULUM ANGLE` the angle of pendulum in different images are almost the same. Meanwhile, we also observe that the `SHADOW LOCATION` and `SHADOW LENGTH` change in a correct way that aligns with the physics law.
- CelabA: When we intervene the cause concept `SMILE`, the status of `MOUTH_OPEN` also changes. In contrast, intervening effect concept `MOUTH_OPEN` does not cause the cause concept `SMILE` to change.

<span class="remark">(So they don't seem to claim that they can change the cause without effects being affected as well, as I interpreted DEAR because of ambiguous language. When a parent is intervened upon, the children also get affected)</span>

Todo sat: answer these

- How is $q_\phi(z\vert x, u)$ and $q_\phi(\epsilon \vert x, u)$ implemented in the network ?

Looking at Fig 2 in paper and Eq 2 and reading the last para of Sec 3.2 leads me to believe that they are interpreting the equation $\textbf{z} = \textbf{A}^T \textbf{z} + \epsilon$ in a strange way. I think they identify the LHS z with the left-half of their architecture and the RHS z with right-half of their architecture, as shown in Fig 2.
This probably also explains why they "manipulate both input and output nodes of the SCM layer" in Sec 6.2.  







